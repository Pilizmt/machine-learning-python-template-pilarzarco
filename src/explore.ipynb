{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Airbnb en Nueva York"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Una empresa ha recolectado la información del alquiler de viviendas en Nueva York a través de la aplicación Airbnb durante el año 2019. Este conjunto de datos se utilizó para entrenar modelos de Machine Learning durante ese año, en una competición en abierto.\n",
                "\n",
                "Ahora lo utilizaremos para llevar a cabo un estudio acerca de las variables que componen el dataset a fin de comprenderlo y obtener conclusiones sobre él."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Pasos que tenemos que seguir para llevar a cabo el estudio en profundidad:\n",
                "\n",
                "- planteamiento del problema y recopilación de datos\n",
                "\n",
                "- Exploración y limpieza de datos\n",
                "\n",
                "- Análisis de variables univariadas\n",
                "\n",
                "- Análisis de variables multivariadas\n",
                "\n",
                "- ingeniería de funciones\n",
                "\n",
                "- selección de funciones\n",
                "\n",
                "Después de la implementación y adopción de estos pasos, estaremos listos para entrenar el modelo."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Paso 1: Carga del conjunto de datos\n",
                "Puedes descargar el conjunto de datos directamente desde Kaggle.com o en el siguiente enlace: https://raw.githubusercontent.com/4GeeksAcademy/data-preprocessing-project-tutorial/main/AB_NYC_2019.csv. Almacena los datos en crudo en la carpeta ./data/raw.\n",
                "\n",
                "\n",
                "Opcional, para descargar el archivo.csv desde la terminal: wget https://raw.githubusercontent.com/4GeeksAcademy/data-preprocessing-project-tutorial/main/AB_NYC_2019.csv.\n",
                "\n",
                "Opcional, para mover a la carpeta src desde la terminal: mv AB_NYC_2019.csv ./data/raw/\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "Abnb_df = pd.read_csv(\"/workspaces/machine-learning-python-template-pilarzarco/data/AB_NYC_2019.csv\")\n",
                "\n",
                "# Dividir el conjunto de datos en entrenamiento y prueba\n",
                "train_data, test_data = train_test_split(Abnb_df, test_size=0.2, random_state=42)\n",
                "\n",
                "# Guardar los conjuntos de entrenamiento y prueba como archivos CSV\n",
                "train_data.to_csv(\"Abnb_train.csv\", index=False)\n",
                "test_data.to_csv(\"Abnb_test.csv\", index=False)\n",
                "\n",
                "Abnb_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Paso 2: Realiza un EDA completo\n",
                "Este paso es vital para asegurar que nos quedamos con las variables estrictamente necesarias y eliminamos las que no son relevantes o no aportan información. Utiliza el Notebook de ejemplo que trabajamos y adáptalo a este caso de uso.\n",
                "\n",
                "Asegúrate de dividir convenientemente el conjunto de datos en train y test como hemos visto en la lección."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dimensiones del Data Frame\n",
                "Abnb_df.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Información sobre el tipo de datos de las columnas, la cantidad de valores no nulos y el uso de memoria\n",
                "Abnb_df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Eliminar columnas que no deseamos\n",
                "Abnb_df = Abnb_df.drop([\"host_name\", \"name\", \"last_review\", \"neighbourhood\", \"host_id\"], axis=1, inplace=False)\n",
                "Abnb_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### - Análisis de variables univariante"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Crear un histograma múltiple sobre variables categóricas\n",
                "fig, axis = plt.subplots(1, 2, figsize=(10, 7))\n",
                "\n",
                "sns.histplot(ax=axis[0], data=Abnb_df, x=\"neighbourhood_group\").set(ylabel=None)\n",
                "sns.histplot(ax=axis[1], data=Abnb_df, x=\"room_type\").set(ylabel=None)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Crear una figura múltiple con histogramas y diagramas de caja sobre variables numéricas\n",
                "fig, axis = plt.subplots(4, 4, figsize = (14, 10), gridspec_kw={'height_ratios': [6, 1, 6, 1]})\n",
                "\n",
                "sns.histplot(ax=axis[0, 0], data=Abnb_df, x=\"price\").set(ylabel=None)\n",
                "sns.boxplot(ax=axis[1, 0], data=Abnb_df, x=\"price\")\n",
                "\n",
                "sns.histplot(ax=axis[0, 1], data=Abnb_df, x=\"availability_365\").set(ylabel=None)\n",
                "sns.boxplot(ax=axis[1, 1], data=Abnb_df, x=\"availability_365\")\n",
                "\n",
                "sns.histplot(ax=axis[0, 2], data=Abnb_df, x=\"minimum_nights\")\n",
                "sns.boxplot(ax=axis[1, 2], data=Abnb_df, x=\"minimum_nights\")\n",
                "\n",
                "sns.histplot(ax=axis[0, 3], data=Abnb_df, x=\"calculated_host_listings_count\")\n",
                "sns.boxplot(ax=axis[1, 3], data=Abnb_df, x=\"calculated_host_listings_count\")\n",
                "\n",
                "sns.histplot(ax=axis[2, 0], data=Abnb_df, x=\"latitude\")\n",
                "sns.boxplot(ax=axis[3, 0], data=Abnb_df, x=\"latitude\")\n",
                "\n",
                "sns.histplot(ax=axis[2, 1], data=Abnb_df, x=\"longitude\")\n",
                "sns.boxplot(ax=axis[3, 1], data=Abnb_df, x=\"longitude\")\n",
                "\n",
                "sns.histplot(ax=axis[2, 2], data=Abnb_df, x=\"number_of_reviews\").set(ylabel=None)\n",
                "sns.boxplot(ax=axis[3, 2], data=Abnb_df, x=\"number_of_reviews\")\n",
                "\n",
                "sns.boxplot(ax=axis[2, 3], data=Abnb_df, x=\"reviews_per_month\").set(ylabel=None)\n",
                "sns.boxplot(ax=axis[3, 3], data=Abnb_df, x=\"reviews_per_month\")\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cambiamos los valores de las columnas con formato string por valores numéricos\n",
                "Abnb_df['room_type_n'] = pd.factorize(Abnb_df['room_type'])[0]\n",
                "Abnb_df['neighbourhood_group_n'] = pd.factorize(Abnb_df['neighbourhood_group'])[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Análisis de correlación\n",
                "fig, axis = plt.subplots(figsize = (10, 7))\n",
                "sns.heatmap(Abnb_df[[\"id\", \"neighbourhood_group_n\", \"latitude\", \"longitude\", \"room_type_n\", \"price\", \"minimum_nights\", \"number_of_reviews\", \"reviews_per_month\", \"calculated_host_listings_count\", \"availability_365\"]].corr(), annot = True, fmt = \".2f\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### - Análisis de variables multivariante"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Comenzamos con el análisis numérico-numérico\n",
                "\n",
                "fig, axis = plt.subplots(4, 4, figsize=(40,30))\n",
                "\n",
                "# Crear un diagrama de dispersión múltiple\n",
                "\n",
                "# Barrio y precio\n",
                "sns.regplot(ax = axis[0, 0], data = Abnb_df, x = \"price\", y = \"neighbourhood_group_n\").set(ylabel=None)\n",
                "sns.heatmap(Abnb_df[[\"neighbourhood_group_n\", \"price\"]].corr(), annot = True, fmt = \".2f\", ax = axis[1, 0], cbar = False)\n",
                "\n",
                "# Barrio y tipo de habitación\n",
                "sns.regplot(ax = axis[0, 1], data = Abnb_df, x = \"room_type_n\", y = \"neighbourhood_group_n\").set(ylabel=None)\n",
                "sns.heatmap(Abnb_df[[\"neighbourhood_group_n\", \"room_type_n\"]].corr(), annot = True, fmt = \".2f\", ax = axis[1, 1], cbar = False)\n",
                "\n",
                "# Tipo de habitación y precio\n",
                "sns.regplot(ax = axis[0, 2], data = Abnb_df, x = \"price\", y = \"room_type_n\").set(ylabel=None)\n",
                "sns.heatmap(Abnb_df[[\"room_type_n\", \"price\"]].corr(), annot = True, fmt = \".2f\", ax = axis[1, 2], cbar = False)\n",
                "\n",
                "# Barrio y latitud\n",
                "sns.regplot(ax = axis[0, 3], data = Abnb_df, x = \"latitude\", y = \"neighbourhood_group_n\").set(ylabel=None)\n",
                "sns.heatmap(Abnb_df[[\"neighbourhood_group_n\", \"latitude\"]].corr(), annot = True, fmt = \".2f\", ax = axis[1, 3], cbar = False)\n",
                "\n",
                "# Barrio y longitud\n",
                "sns.regplot(ax = axis[2, 0], data = Abnb_df, x = \"longitude\", y = \"neighbourhood_group_n\").set(ylabel=None)\n",
                "sns.heatmap(Abnb_df[[\"neighbourhood_group_n\", \"longitude\"]].corr(), annot = True, fmt = \".2f\", ax = axis[3, 0], cbar = False)\n",
                "\n",
                "# Barrio por opiniones por mes\n",
                "sns.regplot(ax = axis[2, 1], data = Abnb_df, x = \"reviews_per_month\", y = \"neighbourhood_group_n\").set(ylabel=None)\n",
                "sns.heatmap(Abnb_df[[\"neighbourhood_group_n\", \"reviews_per_month\"]].corr(), annot = True, fmt = \".2f\", ax = axis[3, 1], cbar = False)\n",
                "\n",
                "# Número de opiniones por opiniones por mes\n",
                "sns.regplot(ax = axis[2, 2], data = Abnb_df, x = \"reviews_per_month\", y = \"number_of_reviews\").set(ylabel=None)\n",
                "sns.heatmap(Abnb_df[[\"number_of_reviews\", \"reviews_per_month\"]].corr(), annot = True, fmt = \".2f\", ax = axis[3, 2], cbar = False)\n",
                "\n",
                "# Mínimo de noches por disponibilidad\n",
                "sns.regplot(ax = axis[2, 3], data = Abnb_df, x = \"minimum_nights\", y = \"availability_365\").set(ylabel=None)\n",
                "sns.heatmap(Abnb_df[[\"availability_365\", \"minimum_nights\"]].corr(), annot = True, fmt = \".2f\", ax = axis[3, 3], cbar = False)\n",
                "\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# matriz de gráficos de dispersión\n",
                "sns.pairplot(Abnb_df)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### - Análisis de valores atípicos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# El análisis descriptivo \n",
                "Abnb_df.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Eliminar valores con valor cero en alguna columna en este caso \"price\"\n",
                "Abnb_df = Abnb_df[Abnb_df['price'] != 0]\n",
                "Abnb_df.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Diagramas de cajas de las variables\n",
                "fig, axis = plt.subplots(4, 3, figsize = (15, 10))\n",
                "\n",
                "sns.boxplot(ax = axis[0, 0], data = Abnb_df, y = \"latitude\")\n",
                "sns.boxplot(ax = axis[0, 1], data = Abnb_df, y = \"longitude\")\n",
                "sns.boxplot(ax = axis[0, 2], data = Abnb_df, y = \"price\")\n",
                "sns.boxplot(ax = axis[1, 0], data = Abnb_df, y = \"minimum_nights\")\n",
                "sns.boxplot(ax = axis[1, 1], data = Abnb_df, y = \"number_of_reviews\")\n",
                "sns.boxplot(ax = axis[1, 2], data = Abnb_df, y = \"reviews_per_month\")\n",
                "sns.boxplot(ax = axis[2, 0], data = Abnb_df, y = \"calculated_host_listings_count\")\n",
                "sns.boxplot(ax = axis[2, 1], data = Abnb_df, y = \"neighbourhood_group_n\")\n",
                "sns.boxplot(ax = axis[2, 2], data = Abnb_df, y = \"room_type_n\")\n",
                "sns.boxplot(ax = axis[3, 0], data = Abnb_df, y = \"availability_365\")\n",
                "\n",
                "plt.tight_layout()\n",
                "fig.delaxes(axis[3, 1])\n",
                "fig.delaxes(axis[3, 2])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fare_stats = Abnb_df[[\"price\", \"minimum_nights\"]].describe()\n",
                "fare_stats"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### - Calcular los límites superior e inferior para identificar outliers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calcular las estadísticas descriptivas para las columnas \"price\" y \"minimum_nights\"\n",
                "fare_stats = Abnb_df[[\"price\", \"minimum_nights\"]].describe()\n",
                "\n",
                "# Imprimir las estadísticas descriptivas\n",
                "print(fare_stats)\n",
                "\n",
                "# Calcular el rango intercuartílico (IQR)\n",
                "fare_iqr_price = fare_stats.loc[\"75%\", \"price\"] - fare_stats.loc[\"25%\", \"price\"]\n",
                "fare_iqr_nights = fare_stats.loc[\"75%\", \"minimum_nights\"] - fare_stats.loc[\"25%\", \"minimum_nights\"]\n",
                "\n",
                "# Calcular los límites superior e inferior para identificar outliers\n",
                "upper_limit_price = fare_stats.loc[\"75%\", \"price\"] + 1.5 * fare_iqr_price\n",
                "lower_limit_price = fare_stats.loc[\"25%\", \"price\"] - 1.5 * fare_iqr_price\n",
                "\n",
                "upper_limit_nights = fare_stats.loc[\"75%\", \"minimum_nights\"] + 1.5 * fare_iqr_nights\n",
                "lower_limit_nights = fare_stats.loc[\"25%\", \"minimum_nights\"] - 1.5 * fare_iqr_nights\n",
                "\n",
                "print(f\"Los límites superior e inferior para encontrar valores atípicos en 'price son  {round(upper_limit_price, 2)} and {round(lower_limit_price, 2)}, con un rango intercuartílico de {round(fare_iqr_price, 2)}\")\n",
                "print(f\"Los límites superior e inferior para encontrar valores atípicos en 'minimum_nights son {round(upper_limit_nights, 2)} and {round(lower_limit_nights, 2)}, con un rango intercuartílico de {round(fare_iqr_nights, 2)}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### - Análisis de valores faltantes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#  Obtener valores faltantes\n",
                "Abnb_df_ = Abnb_df.isnull().sum().sort_values(ascending=False)\n",
                "Abnb_df_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Porcentaje de valores faltantes en cada columna\n",
                "Abnb_df.isnull().sum().sort_values(ascending=False) / len(Abnb_df_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imputación numérica sobre \"reviews_per_month\"\n",
                "Abnb_df[\"reviews_per_month\"].fillna(Abnb_df[\"reviews_per_month\"].median(), inplace = True)\n",
                "# Abnb_df[\"reviews_per_month\"].fillna(Abnb_df[\"reviews_per_month\"].mode()[0], inplace = True)\n",
                "# Abnb_df[\"reviews_per_month\"].fillna(Abnb_df[\"reviews_per_month\"].mean(), inplace = True)\n",
                "\n",
                "Abnb_df.isnull().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Inferencia de nuevas características\n",
                "Abnb_df[\"FamMembers\"] = Abnb_df[\"SibSp\"] + Abnb_df[\"Parch\"]\n",
                "Abnb_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Escalado de características\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "num_variables = [\"Pclass\", \"Age\", \"Fare\", \"Sex_n\", \"Embarked_n\", \"FamMembers\"]\n",
                "\n",
                "scaler = StandardScaler()\n",
                "norm_features = scaler.fit_transform(Abnb_df[num_variables])\n",
                "total_data_norm = pd.DataFrame(norm_features, index = Abnb_df.index, columns = num_variables)\n",
                "total_data_norm[\"Survived\"] = Abnb_df[\"Survived\"]\n",
                "total_data_norm.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Escala mín.-máx\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "\n",
                "num_variables = [\"Pclass\", \"Age\", \"Fare\", \"Sex_n\", \"Embarked_n\", \"FamMembers\"]\n",
                "\n",
                "scaler = MinMaxScaler()\n",
                "scal_features = scaler.fit_transform(Abnb_df[num_variables])\n",
                "total_data_scal = pd.DataFrame(scal_features, index = Abnb_df.index, columns = num_variables)\n",
                "total_data_scal[\"Survived\"] = Abnb_df[\"Survived\"]\n",
                "total_data_scal.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Selección de funciones"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.feature_selection import chi2, SelectKBest\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# We divide the dataset into training and test samples.\n",
                "X = total_data_scal.drop(\"Survived\", axis = 1)\n",
                "y = total_data_scal[\"Survived\"]\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
                "\n",
                "# With a value of k = 5 we implicitly mean that we want to remove 2 features from the dataset\n",
                "selection_model = SelectKBest(chi2, k = 5)\n",
                "selection_model.fit(X_train, y_train)\n",
                "ix = selection_model.get_support()\n",
                "X_train_sel = pd.DataFrame(selection_model.transform(X_train), columns = X_train.columns.values[ix])\n",
                "X_test_sel = pd.DataFrame(selection_model.transform(X_test), columns = X_test.columns.values[ix])\n",
                "\n",
                "X_train_sel.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_test_sel.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train_sel[\"Survived\"] = list(y_train)\n",
                "X_test_sel[\"Survived\"] = list(y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train_sel.to_csv(\"/workspaces/machine-learning-content/assets/clean_titanic_train.csv\", index=False)\n",
                "X_test_sel.to_csv(\"/workspaces/machine-learning-content/assets/clean_titanic_test.csv\", index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Paso 3: Guarda el conjunto de datos procesado\n",
                "Después del EDA puedes guardar los datos en la carpeta ./data/processed. Asegúrate de agregar la carpeta de los datos en el .gitignore. Los datos al igual que los modelos no se deben subir a git."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Asumiendo que Abnb_df es tu DataFrame procesado\n",
                "# Este código guardará tu DataFrame procesado como un archivo CSV en la ruta especificada.\n",
                "ruta_guardado = \"./data/processed/Abnb_dataset_procesado.csv\"\n",
                "Abnb_df.to_csv(ruta_guardado, index=False)\n",
                "\n",
                "# Asegúrate de que tu archivo .gitignore incluya la línea correspondiente a la carpeta ./data/processed.\n",
                "# Si aún no tienes un archivo .gitignore, créalo en la raíz de tu proyecto y agrega la siguiente línea:, en el bash: /data/processed/\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
